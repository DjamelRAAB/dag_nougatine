
End of LogType:prelaunch.err
******************************************************************************

Container: container_1606160497897_0548_01_000001 on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud_8041
LogAggregationType: AGGREGATED
=======================================================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Thu Dec 10 08:12:35 +0000 2020
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_1606160497897_0548_01_000001 on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud_8041
LogAggregationType: AGGREGATED
=======================================================================================================================
LogType:stderr
LogLastModifiedTime:Thu Dec 10 08:12:35 +0000 2020
LogLength:105241
LogContents:
20/12/10 08:11:27 INFO util.SignalUtils: Registered signal handler for TERM
20/12/10 08:11:27 INFO util.SignalUtils: Registered signal handler for HUP
20/12/10 08:11:27 INFO util.SignalUtils: Registered signal handler for INT
20/12/10 08:11:27 INFO spark.SecurityManager: Changing view acls to: yarn,iabd2_group6
20/12/10 08:11:27 INFO spark.SecurityManager: Changing modify acls to: yarn,iabd2_group6
20/12/10 08:11:27 INFO spark.SecurityManager: Changing view acls groups to: 
20/12/10 08:11:27 INFO spark.SecurityManager: Changing modify acls groups to: 
20/12/10 08:11:27 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, iabd2_group6); groups with view permissions: Set(); users  with modify permissions: Set(yarn, iabd2_group6); groups with modify permissions: Set()
20/12/10 08:11:28 INFO yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1606160497897_0548_000001
20/12/10 08:11:28 INFO yarn.ApplicationMaster: Starting the user application in a separate Thread
20/12/10 08:11:28 INFO yarn.ApplicationMaster: Waiting for spark context initialization...
20/12/10 08:11:28 INFO spark.SparkContext: Running Spark version 2.4.0-cdh6.3.2
20/12/10 08:11:28 INFO spark.SparkContext: Submitted application: collect_data
20/12/10 08:11:29 INFO spark.SecurityManager: Changing view acls to: yarn,iabd2_group6
20/12/10 08:11:29 INFO spark.SecurityManager: Changing modify acls to: yarn,iabd2_group6
20/12/10 08:11:29 INFO spark.SecurityManager: Changing view acls groups to: 
20/12/10 08:11:29 INFO spark.SecurityManager: Changing modify acls groups to: 
20/12/10 08:11:29 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, iabd2_group6); groups with view permissions: Set(); users  with modify permissions: Set(yarn, iabd2_group6); groups with modify permissions: Set()
20/12/10 08:11:29 INFO util.Utils: Successfully started service 'sparkDriver' on port 42493.
20/12/10 08:11:29 INFO spark.SparkEnv: Registering MapOutputTracker
20/12/10 08:11:29 INFO spark.SparkEnv: Registering BlockManagerMaster
20/12/10 08:11:29 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/12/10 08:11:29 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/12/10 08:11:29 INFO storage.DiskBlockManager: Created local directory at /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/blockmgr-a824b300-a2f6-4b7b-b91a-356877359ccf
20/12/10 08:11:29 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB
20/12/10 08:11:29 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/12/10 08:11:29 INFO util.log: Logging initialized @3320ms
20/12/10 08:11:29 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/12/10 08:11:29 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
20/12/10 08:11:29 INFO server.Server: Started @3441ms
20/12/10 08:11:29 INFO server.AbstractConnector: Started ServerConnector@463b2159{HTTP/1.1,[http/1.1]}{0.0.0.0:40478}
20/12/10 08:11:29 INFO util.Utils: Successfully started service 'SparkUI' on port 40478.
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4c40f09e{/jobs,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@441e864a{/jobs/json,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2d519a97{/jobs/job,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@295395f6{/jobs/job/json,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@19cf6a40{/stages,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@38ebdecc{/stages/json,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5feb8a16{/stages/stage,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ea6002f{/stages/stage/json,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d9e9cd7{/stages/pool,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1505fad4{/stages/pool/json,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@702f35b0{/storage,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2e56e4e2{/storage/json,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@37b7addb{/storage/rdd,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d5e22a3{/storage/rdd/json,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4d5140d{/environment,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1dbd9181{/environment/json,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@17ee3e98{/executors,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6b595dfc{/executors/json,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@478059e6{/executors/threadDump,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3640e90e{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50bc0ba0{/static,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@33dd9ad6{/,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@76af8751{/api,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3fccb64e{/jobs/job/kill,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5f76e0f6{/stages/stage/kill,null,AVAILABLE,@Spark}
20/12/10 08:11:29 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:40478
20/12/10 08:11:30 INFO cluster.YarnClusterScheduler: Created YarnClusterScheduler
20/12/10 08:11:30 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:30 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/12/10 08:11:30 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1606160497897_0548 and attemptId Some(appattempt_1606160497897_0548_000001)
20/12/10 08:11:30 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38827.
20/12/10 08:11:30 INFO netty.NettyBlockTransferService: Server created on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827
20/12/10 08:11:30 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/12/10 08:11:30 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud, 38827, None)
20/12/10 08:11:30 INFO storage.BlockManagerMasterEndpoint: Registering block manager b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 with 366.3 MB RAM, BlockManagerId(driver, b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud, 38827, None)
20/12/10 08:11:30 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud, 38827, None)
20/12/10 08:11:30 INFO storage.BlockManager: external shuffle service port = 7337
20/12/10 08:11:30 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud, 38827, None)
20/12/10 08:11:30 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/12/10 08:11:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@526ab042{/metrics/json,null,AVAILABLE,@Spark}
20/12/10 08:11:31 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:31 INFO scheduler.EventLoggingListener: Logging events to hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/spark/applicationHistory/application_1606160497897_0548_1
20/12/10 08:11:31 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/12/10 08:11:31 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
20/12/10 08:11:31 INFO spark.SparkContext: Registered listener com.cloudera.spark.lineage.NavigatorAppListener
20/12/10 08:11:32 INFO client.RMProxy: Connecting to ResourceManager at d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud/10.66.41.193:8030
20/12/10 08:11:32 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:32 INFO yarn.YarnRMClient: Registering the ApplicationMaster
20/12/10 08:11:32 INFO yarn.ApplicationMaster: Preparing Local resources
20/12/10 08:11:32 INFO yarn.ApplicationMaster: 
===============================================================================
YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/jars/*<CPS>{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/hive/*<CPS>$HADOOP_CLIENT_CONF_DIR<CPS>$HADOOP_COMMON_HOME/*<CPS>$HADOOP_COMMON_HOME/lib/*<CPS>$HADOOP_HDFS_HOME/*<CPS>$HADOOP_HDFS_HOME/lib/*<CPS>$HADOOP_YARN_HOME/*<CPS>$HADOOP_YARN_HOME/lib/*<CPS>$HADOOP_CLIENT_CONF_DIR<CPS>$PWD/mr-framework/*<CPS>$MR2_CLASSPATH<CPS>{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/accessors-smart-1.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/accessors-smart.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/asm-5.0.4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/asm.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/avro.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/aws-java-sdk-bundle-1.11.271.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/aws-java-sdk-bundle.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/azure-data-lake-store-sdk-2.2.9.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/azure-data-lake-store-sdk.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-beanutils-1.9.4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-beanutils.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-cli-1.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-cli.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-codec-1.11.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-codec.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-collections-3.2.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-collections.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-compress-1.18.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-compress.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-configuration2-2.1.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-configuration2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-io-2.6.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-io.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang-2.6.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang3-3.7.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-logging-1.1.3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-logging.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-math3-3.1.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-math3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-net-3.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-net.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-client-2.12.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-client.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-framework-2.12.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-framework.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-recipes-2.12.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-recipes.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/gson-2.2.4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/gson.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/guava-11.0.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/guava.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-annotations-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-annotations.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-auth-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-auth.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-aws-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-aws.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-datalake-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-datalake.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-common-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-common.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-hdfs-client-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-hdfs-client.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-common-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-common.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-core-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-core.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-jobclient-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-jobclient.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-api-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-client-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-client.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-common-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-common.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/htrace-core4-4.1.0-incubating.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/htrace-core4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpclient-4.5.3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpclient.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpcore-4.4.6.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpcore.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/javax.activation-api-1.2.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/javax.activation-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jaxb-api-2.2.11.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jaxb-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jcip-annotations-1.0-1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jcip-annotations.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/json-smart-2.3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/json-smart.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsp-api-2.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsp-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr305-3.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr305.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr311-api-1.1.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr311-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-admin-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-admin.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-client-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-client.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-common-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-common.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-core-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-core.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-crypto-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-crypto.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-identity-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-identity.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-server-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-server.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-simplekdc-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-simplekdc.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-util-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-util.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-asn1-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-asn1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-config-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-config.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-pkix-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-pkix.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-util-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-util.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-xdr-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-xdr.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/log4j-1.2.17.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/log4j.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/nimbus-jose-jwt-4.41.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/nimbus-jose-jwt.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okhttp-2.7.5.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okhttp.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okio-1.6.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okio.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/paranamer-2.8.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/paranamer.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/protobuf-java-2.5.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/protobuf-java.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/re2j-1.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/re2j.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/snappy-java-1.1.4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/snappy-java.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/stax2-api-3.1.4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/stax2-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/wildfly-openssl-1.0.4.Final.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/wildfly-openssl.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/woodstox-core-5.0.3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/woodstox-core.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/xz-1.6.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/xz.jar<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    MKL_NUM_THREADS -> 1
    SPARK_DIST_CLASSPATH -> /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/accessors-smart-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/accessors-smart.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/asm-5.0.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/asm.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/avro.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/aws-java-sdk-bundle-1.11.271.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/aws-java-sdk-bundle.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/azure-data-lake-store-sdk-2.2.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/azure-data-lake-store-sdk.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-beanutils-1.9.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-beanutils.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-cli.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-codec-1.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-codec.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-collections.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-compress-1.18.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-compress.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-configuration2-2.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-configuration2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-io-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-io.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang3-3.7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-logging.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-math3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-net.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-client-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-framework-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-framework.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-recipes-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-recipes.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/gson.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/guava.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-annotations-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-annotations.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-auth-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-auth.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-aws-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-aws.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-datalake-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-datalake.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-hdfs-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-hdfs-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-core-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-core.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-jobclient-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-jobclient.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-api-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/htrace-core4-4.1.0-incubating.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/htrace-core4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpclient-4.5.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpclient.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpcore-4.4.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpcore.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/javax.activation-api-1.2.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/javax.activation-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jaxb-api-2.2.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jaxb-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jcip-annotations-1.0-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jcip-annotations.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/json-smart-2.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/json-smart.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsp-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr305.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr311-api-1.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr311-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-admin-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-admin.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-client-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-common-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-core-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-core.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-crypto-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-crypto.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-identity-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-identity.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-server-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-server.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-simplekdc-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-simplekdc.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-util.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-asn1-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-asn1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-config-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-config.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-pkix-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-pkix.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-util.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-xdr-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-xdr.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/log4j.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/nimbus-jose-jwt-4.41.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/nimbus-jose-jwt.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okhttp-2.7.5.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okhttp.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okio-1.6.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okio.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/paranamer-2.8.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/paranamer.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/protobuf-java.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/re2j-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/re2j.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/snappy-java-1.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/snappy-java.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/stax2-api-3.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/stax2-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/wildfly-openssl-1.0.4.Final.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/wildfly-openssl.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/woodstox-core-5.0.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/woodstox-core.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/xz-1.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/xz.jar
    SPARK_YARN_STAGING_DIR -> hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/.sparkStaging/application_1606160497897_0548
    SPARK_USER -> iabd2_group6
    PYTHONPATH -> /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/python/lib/py4j-0.10.7-src.zip<CPS>/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/python/lib/pyspark.zip
    OPENBLAS_NUM_THREADS -> 1

  command:
    LD_LIBRARY_PATH=\"{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native:$LD_LIBRARY_PATH\" \ 
      {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx1024m \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.authenticate=false' \ 
      '-Dspark.driver.port=42493' \ 
      '-Dspark.network.crypto.enabled=false' \ 
      '-Dspark.shuffle.service.port=7337' \ 
      '-Dspark.ui.port=0' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.CoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:42493 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      1 \ 
      --app-id \ 
      application_1606160497897_0548 \ 
      --user-class-path \ 
      file:$PWD/__app__.jar \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    __spark_conf__ -> resource { scheme: "hdfs" host: "d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud" port: 8020 file: "/user/iabd2_group6/.sparkStaging/application_1606160497897_0548/__spark_conf__.zip" } size: 163520 timestamp: 1607587891930 type: ARCHIVE visibility: PRIVATE

===============================================================================
20/12/10 08:11:32 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/12/10 08:11:32 INFO conf.Configuration: resource-types.xml not found
20/12/10 08:11:32 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/12/10 08:11:32 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:42493)
20/12/10 08:11:32 INFO yarn.ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
20/12/10 08:11:32 INFO cluster.YarnClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
20/12/10 08:11:32 INFO cluster.YarnClusterScheduler: YarnClusterScheduler.postStartHook done
20/12/10 08:11:32 INFO internal.SharedState: loading hive config file: file:/yarn/nm/usercache/iabd2_group6/filecache/95/__spark_conf__.zip/__hadoop_conf__/hive-site.xml
20/12/10 08:11:32 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('/user/hive/warehouse') to the value of spark.sql.warehouse.dir ('hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/hive/warehouse/').
20/12/10 08:11:32 INFO internal.SharedState: Warehouse path is 'hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/hive/warehouse/'.
20/12/10 08:11:32 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.
20/12/10 08:11:32 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@34fd36cf{/SQL,null,AVAILABLE,@Spark}
20/12/10 08:11:32 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.
20/12/10 08:11:32 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7815edba{/SQL/json,null,AVAILABLE,@Spark}
20/12/10 08:11:32 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.
20/12/10 08:11:32 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@16a49426{/SQL/execution,null,AVAILABLE,@Spark}
20/12/10 08:11:32 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.
20/12/10 08:11:32 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@57b71761{/SQL/execution/json,null,AVAILABLE,@Spark}
20/12/10 08:11:32 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.
20/12/10 08:11:32 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@623dcfa7{/static/sql,null,AVAILABLE,@Spark}
20/12/10 08:11:33 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:33 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
20/12/10 08:11:33 INFO __main__: pyspark script logger initialized
20/12/10 08:11:34 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:35 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:36 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:36 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:36 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
20/12/10 08:11:36 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:36 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:37 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:37 INFO codegen.CodeGenerator: Code generated in 397.224378 ms
20/12/10 08:11:37 INFO codegen.CodeGenerator: Code generated in 47.808128 ms
20/12/10 08:11:37 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 473.6 KB, free 365.8 MB)
20/12/10 08:11:38 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:38 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 49.8 KB, free 365.8 MB)
20/12/10 08:11:38 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 366.3 MB)
20/12/10 08:11:38 INFO spark.SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:38 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:38 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:38 INFO scheduler.DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:38 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:38 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:38 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:38 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:38 INFO yarn.YarnAllocator: Driver requested a total number of 1 executor(s).
20/12/10 08:11:38 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)
20/12/10 08:11:38 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 365.8 MB)
20/12/10 08:11:38 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 365.8 MB)
20/12/10 08:11:38 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 4.5 KB, free: 366.2 MB)
20/12/10 08:11:38 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:38 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:38 INFO cluster.YarnClusterScheduler: Adding task set 0.0 with 1 tasks
20/12/10 08:11:38 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 1 core(s) and 1408 MB memory (including 384 MB of overhead)
20/12/10 08:11:38 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:39 INFO yarn.YarnAllocator: Submitted container request for host bab6e83c-2a27-42b6-b0f0-b66263e83587.priv.instances.scw.cloud,b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud,e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud.
20/12/10 08:11:39 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:39 INFO yarn.YarnAllocator: Launching container container_1606160497897_0548_01_000002 on host e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud for executor with ID 1
20/12/10 08:11:39 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/12/10 08:11:40 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:41 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:42 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:43 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:11:43 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.69.120.23:59360) with ID 1
20/12/10 08:11:43 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1)
20/12/10 08:11:43 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8400 bytes)
20/12/10 08:11:43 INFO storage.BlockManagerMasterEndpoint: Registering block manager e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 with 366.3 MB RAM, BlockManagerId(1, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, 41795, None)
20/12/10 08:11:44 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 4.5 KB, free: 366.3 MB)
20/12/10 08:11:45 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 366.2 MB)
20/12/10 08:11:47 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3795 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:47 INFO cluster.YarnClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/12/10 08:11:47 INFO scheduler.DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 8.470 s
20/12/10 08:11:47 INFO scheduler.DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 8.639895 s
20/12/10 08:11:47 INFO yarn.YarnAllocator: Driver requested a total number of 0 executor(s).
20/12/10 08:11:47 INFO conf.HiveConf: Found configuration file file:/yarn/nm/usercache/iabd2_group6/filecache/95/__spark_conf__.zip/__hadoop_conf__/hive-site.xml
20/12/10 08:11:47 INFO hive.HiveUtils: Initializing HiveMetastoreConnection version 2.1 using Spark classes.
20/12/10 08:11:47 INFO conf.HiveConf: Found configuration file file:/yarn/nm/usercache/iabd2_group6/filecache/95/__spark_conf__.zip/__hadoop_conf__/hive-site.xml
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 12
20/12/10 08:11:47 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 in memory (size: 4.5 KB, free: 366.3 MB)
20/12/10 08:11:47 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 in memory (size: 4.5 KB, free: 366.3 MB)
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 15
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 9
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 18
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 32
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 13
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 23
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 11
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 27
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 16
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 14
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 20
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 10
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 22
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 17
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 24
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 21
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 25
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 29
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 30
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 28
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 31
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 26
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 19
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 8
20/12/10 08:11:47 INFO spark.ContextCleaner: Cleaned accumulator 7
20/12/10 08:11:48 INFO session.SessionState: Created local directory: /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/container_1606160497897_0548_01_000001/tmp/yarn
20/12/10 08:11:48 INFO session.SessionState: Created HDFS directory: /tmp/hive/iabd2_group6/ad9efaa5-683e-4f71-933d-a6cdc652aa1f
20/12/10 08:11:48 INFO session.SessionState: Created local directory: /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/container_1606160497897_0548_01_000001/tmp/yarn/ad9efaa5-683e-4f71-933d-a6cdc652aa1f
20/12/10 08:11:48 INFO session.SessionState: Created HDFS directory: /tmp/hive/iabd2_group6/ad9efaa5-683e-4f71-933d-a6cdc652aa1f/_tmp_space.db
20/12/10 08:11:48 INFO client.HiveClientImpl: Warehouse location for Hive client (version 2.1.1) is hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/hive/warehouse/
20/12/10 08:11:49 INFO hive.metastore: HMS client filtering is enabled.
20/12/10 08:11:49 INFO hive.metastore: Trying to connect to metastore with URI thrift://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:9083
20/12/10 08:11:49 INFO hive.metastore: Opened a connection to metastore, current connections: 1
20/12/10 08:11:49 INFO hive.metastore: Connected to metastore.
20/12/10 08:11:49 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:49 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:11:49 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:49 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:49 INFO codegen.CodeGenerator: Code generated in 14.791972 ms
20/12/10 08:11:49 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 473.6 KB, free 365.3 MB)
20/12/10 08:11:49 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 49.8 KB, free 365.3 MB)
20/12/10 08:11:49 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 366.2 MB)
20/12/10 08:11:49 INFO spark.SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:49 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:49 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:49 INFO scheduler.DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:49 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:49 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:49 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:49 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:49 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.3 KB, free 365.3 MB)
20/12/10 08:11:49 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.1 KB, free 365.3 MB)
20/12/10 08:11:49 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 7.1 KB, free: 366.2 MB)
20/12/10 08:11:49 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:49 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:49 INFO cluster.YarnClusterScheduler: Adding task set 1.0 with 1 tasks
20/12/10 08:11:49 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8400 bytes)
20/12/10 08:11:50 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 7.1 KB, free: 366.2 MB)
20/12/10 08:11:52 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 366.2 MB)
20/12/10 08:11:52 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2311 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:52 INFO cluster.YarnClusterScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/12/10 08:11:52 INFO scheduler.DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 2.331 s
20/12/10 08:11:52 INFO scheduler.DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 2.341532 s
20/12/10 08:11:52 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_albums_releases_full.csv ... OK
20/12/10 08:11:52 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:52 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#50, None)) > 0)
20/12/10 08:11:52 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:52 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:52 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 473.6 KB, free 364.8 MB)
20/12/10 08:11:52 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 49.8 KB, free 364.7 MB)
20/12/10 08:11:52 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 366.1 MB)
20/12/10 08:11:52 INFO spark.SparkContext: Created broadcast 4 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:52 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:52 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:52 INFO scheduler.DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:52 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:52 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:52 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:52 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:52 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.8 KB, free 364.7 MB)
20/12/10 08:11:52 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 364.7 MB)
20/12/10 08:11:52 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 4.5 KB, free: 366.1 MB)
20/12/10 08:11:52 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:52 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:52 INFO cluster.YarnClusterScheduler: Adding task set 2.0 with 1 tasks
20/12/10 08:11:52 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8401 bytes)
20/12/10 08:11:52 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 4.5 KB, free: 366.2 MB)
20/12/10 08:11:52 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 366.1 MB)
20/12/10 08:11:52 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 183 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:52 INFO cluster.YarnClusterScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/12/10 08:11:52 INFO scheduler.DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.232 s
20/12/10 08:11:52 INFO scheduler.DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.244433 s
20/12/10 08:11:52 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:52 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:11:52 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:52 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:52 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 473.6 KB, free 364.3 MB)
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 90
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 45
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 57
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 39
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 77
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 71
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 60
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 40
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 70
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 66
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 61
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 48
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 80
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 84
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 89
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 82
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 62
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 72
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 68
20/12/10 08:11:52 INFO spark.ContextCleaner: Cleaned accumulator 46
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 in memory (size: 49.8 KB, free: 366.2 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 in memory (size: 49.8 KB, free: 366.2 MB)
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 49.8 KB, free 364.7 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 366.1 MB)
20/12/10 08:11:53 INFO spark.SparkContext: Created broadcast 6 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:53 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 56
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 81
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 88
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 67
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 58
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 85
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 65
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 63
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 86
20/12/10 08:11:53 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 in memory (size: 4.5 KB, free: 366.1 MB)
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.2 KB, free 364.7 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 in memory (size: 4.5 KB, free: 366.2 MB)
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.1 KB, free 364.7 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 7.1 KB, free: 366.1 MB)
20/12/10 08:11:53 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:53 INFO cluster.YarnClusterScheduler: Adding task set 3.0 with 1 tasks
20/12/10 08:11:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8401 bytes)
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 55
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 64
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 76
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 94
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 42
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 59
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 79
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 69
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 95
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 52
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 47
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 74
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 43
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 87
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 51
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 93
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 83
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 91
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 50
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 78
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 49
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 92
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 75
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 53
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 44
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 in memory (size: 7.1 KB, free: 366.1 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 in memory (size: 7.1 KB, free: 366.2 MB)
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 73
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 38
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 41
20/12/10 08:11:53 INFO spark.ContextCleaner: Cleaned accumulator 54
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 7.1 KB, free: 366.2 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 366.1 MB)
20/12/10 08:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 169 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:53 INFO scheduler.DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.192 s
20/12/10 08:11:53 INFO cluster.YarnClusterScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.206287 s
20/12/10 08:11:53 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_artists_releases_full.csv ... OK
20/12/10 08:11:53 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:53 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#82, None)) > 0)
20/12/10 08:11:53 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:53 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 473.6 KB, free 364.3 MB)
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 49.8 KB, free 364.2 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 366.1 MB)
20/12/10 08:11:53 INFO spark.SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:53 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:53 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Got job 4 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 8.8 KB, free 364.2 MB)
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.5 KB, free 364.2 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 4.5 KB, free: 366.1 MB)
20/12/10 08:11:53 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:53 INFO cluster.YarnClusterScheduler: Adding task set 4.0 with 1 tasks
20/12/10 08:11:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, RACK_LOCAL, 8400 bytes)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 4.5 KB, free: 366.1 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 366.1 MB)
20/12/10 08:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 141 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:53 INFO cluster.YarnClusterScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/12/10 08:11:53 INFO scheduler.DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0) finished in 0.163 s
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Job 4 finished: csv at NativeMethodAccessorImpl.java:0, took 0.172570 s
20/12/10 08:11:53 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:53 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:11:53 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:53 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 473.6 KB, free 363.8 MB)
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 49.8 KB, free 363.7 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 366.0 MB)
20/12/10 08:11:53 INFO spark.SparkContext: Created broadcast 10 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:53 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:53 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Got job 5 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.3 KB, free 363.7 MB)
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.1 KB, free 363.7 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 7.1 KB, free: 366.0 MB)
20/12/10 08:11:53 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:53 INFO cluster.YarnClusterScheduler: Adding task set 5.0 with 1 tasks
20/12/10 08:11:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, RACK_LOCAL, 8400 bytes)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 7.1 KB, free: 366.1 MB)
20/12/10 08:11:53 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 366.0 MB)
20/12/10 08:11:54 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 213 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:54 INFO cluster.YarnClusterScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/12/10 08:11:54 INFO scheduler.DAGScheduler: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0) finished in 0.236 s
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Job 5 finished: csv at NativeMethodAccessorImpl.java:0, took 0.244333 s
20/12/10 08:11:54 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_tracks_featured_full.csv ... OK
20/12/10 08:11:54 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:54 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#128, None)) > 0)
20/12/10 08:11:54 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:54 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 473.6 KB, free 363.2 MB)
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 49.8 KB, free 363.2 MB)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 366.0 MB)
20/12/10 08:11:54 INFO spark.SparkContext: Created broadcast 12 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:54 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:54 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.8 KB, free 363.2 MB)
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 363.2 MB)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 4.5 KB, free: 366.0 MB)
20/12/10 08:11:54 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:54 INFO cluster.YarnClusterScheduler: Adding task set 6.0 with 1 tasks
20/12/10 08:11:54 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8400 bytes)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 4.5 KB, free: 366.0 MB)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 366.0 MB)
20/12/10 08:11:54 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 106 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:54 INFO cluster.YarnClusterScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/12/10 08:11:54 INFO scheduler.DAGScheduler: ResultStage 6 (csv at NativeMethodAccessorImpl.java:0) finished in 0.119 s
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Job 6 finished: csv at NativeMethodAccessorImpl.java:0, took 0.124650 s
20/12/10 08:11:54 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:54 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:11:54 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:54 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 473.6 KB, free 362.7 MB)
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 49.8 KB, free 362.7 MB)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 365.9 MB)
20/12/10 08:11:54 INFO spark.SparkContext: Created broadcast 14 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:54 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:54 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Got job 7 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Final stage: ResultStage 7 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 13.3 KB, free 362.6 MB)
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.1 KB, free 362.6 MB)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 7.1 KB, free: 365.9 MB)
20/12/10 08:11:54 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:54 INFO cluster.YarnClusterScheduler: Adding task set 7.0 with 1 tasks
20/12/10 08:11:54 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8400 bytes)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 7.1 KB, free: 366.0 MB)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 365.9 MB)
20/12/10 08:11:54 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 191 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:54 INFO cluster.YarnClusterScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/12/10 08:11:54 INFO scheduler.DAGScheduler: ResultStage 7 (csv at NativeMethodAccessorImpl.java:0) finished in 0.206 s
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Job 7 finished: csv at NativeMethodAccessorImpl.java:0, took 0.212392 s
20/12/10 08:11:54 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_tracks_releases_full.csv ... OK
20/12/10 08:11:54 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:54 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#174, None)) > 0)
20/12/10 08:11:54 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:54 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 473.6 KB, free 362.2 MB)
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 49.8 KB, free 362.1 MB)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 365.9 MB)
20/12/10 08:11:54 INFO spark.SparkContext: Created broadcast 16 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:54 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:54 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Got job 8 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 8.8 KB, free 362.1 MB)
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.5 KB, free 362.1 MB)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 4.5 KB, free: 365.9 MB)
20/12/10 08:11:54 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:54 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:54 INFO cluster.YarnClusterScheduler: Adding task set 8.0 with 1 tasks
20/12/10 08:11:54 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8403 bytes)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 4.5 KB, free: 365.9 MB)
20/12/10 08:11:54 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 365.9 MB)
20/12/10 08:11:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 110 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:55 INFO cluster.YarnClusterScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/12/10 08:11:55 INFO scheduler.DAGScheduler: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0) finished in 0.124 s
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Job 8 finished: csv at NativeMethodAccessorImpl.java:0, took 0.127137 s
20/12/10 08:11:55 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:55 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:11:55 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:55 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 473.6 KB, free 361.7 MB)
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 49.8 KB, free 361.6 MB)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:11:55 INFO spark.SparkContext: Created broadcast 18 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:55 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:55 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Got job 9 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Final stage: ResultStage 9 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[44] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 13.2 KB, free 361.6 MB)
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.1 KB, free 361.6 MB)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 7.1 KB, free: 365.8 MB)
20/12/10 08:11:55 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[44] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:55 INFO cluster.YarnClusterScheduler: Adding task set 9.0 with 1 tasks
20/12/10 08:11:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8403 bytes)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 7.1 KB, free: 365.9 MB)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:11:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 152 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:55 INFO cluster.YarnClusterScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/12/10 08:11:55 INFO scheduler.DAGScheduler: ResultStage 9 (csv at NativeMethodAccessorImpl.java:0) finished in 0.165 s
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Job 9 finished: csv at NativeMethodAccessorImpl.java:0, took 0.168003 s
20/12/10 08:11:55 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_playlists_featured_full.csv ... OK
20/12/10 08:11:55 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:55 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#216, None)) > 0)
20/12/10 08:11:55 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:55 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 473.6 KB, free 361.1 MB)
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 49.8 KB, free 361.1 MB)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:11:55 INFO spark.SparkContext: Created broadcast 20 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:55 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:55 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Got job 10 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[48] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 8.8 KB, free 361.1 MB)
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.5 KB, free 361.1 MB)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 4.5 KB, free: 365.8 MB)
20/12/10 08:11:55 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[48] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:55 INFO cluster.YarnClusterScheduler: Adding task set 10.0 with 1 tasks
20/12/10 08:11:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8401 bytes)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 4.5 KB, free: 365.8 MB)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:11:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 102 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:55 INFO cluster.YarnClusterScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/12/10 08:11:55 INFO scheduler.DAGScheduler: ResultStage 10 (csv at NativeMethodAccessorImpl.java:0) finished in 0.117 s
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Job 10 finished: csv at NativeMethodAccessorImpl.java:0, took 0.121935 s
20/12/10 08:11:55 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:11:55 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:11:55 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:11:55 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 473.6 KB, free 360.6 MB)
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 49.8 KB, free 360.5 MB)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 49.8 KB, free: 365.7 MB)
20/12/10 08:11:55 INFO spark.SparkContext: Created broadcast 22 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:55 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:11:55 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Got job 11 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Final stage: ResultStage 11 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[53] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 13.2 KB, free 360.5 MB)
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.1 KB, free 360.5 MB)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 (size: 7.1 KB, free: 365.7 MB)
20/12/10 08:11:55 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1164
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[53] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:11:55 INFO cluster.YarnClusterScheduler: Adding task set 11.0 with 1 tasks
20/12/10 08:11:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8401 bytes)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 7.1 KB, free: 365.8 MB)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 (size: 49.8 KB, free: 365.7 MB)
20/12/10 08:11:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 121 ms on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:11:55 INFO cluster.YarnClusterScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/12/10 08:11:55 INFO scheduler.DAGScheduler: ResultStage 11 (csv at NativeMethodAccessorImpl.java:0) finished in 0.138 s
20/12/10 08:11:55 INFO scheduler.DAGScheduler: Job 11 finished: csv at NativeMethodAccessorImpl.java:0, took 0.144070 s
20/12/10 08:11:55 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_artists_featured_full.csv ... OK
20/12/10 08:11:55 INFO __main__: get_top_artist_from_top_playlist .. ok
20/12/10 08:11:55 ERROR yarn.ApplicationMaster: User application exited with status 1
20/12/10 08:11:55 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 1, (reason: User application exited with status 1)
20/12/10 08:11:55 INFO spark.SparkContext: Invoking stop() from shutdown hook
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 229
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 254
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 330
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 191
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 299
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 325
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 131
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 328
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 in memory (size: 7.1 KB, free: 365.7 MB)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 in memory (size: 7.1 KB, free: 365.7 MB)
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 192
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 350
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 234
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 261
20/12/10 08:11:55 INFO spark.ContextCleaner: Cleaned accumulator 275
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 in memory (size: 7.1 KB, free: 365.7 MB)
20/12/10 08:11:55 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 in memory (size: 7.1 KB, free: 365.7 MB)
20/12/10 08:11:55 INFO server.AbstractConnector: Stopped Spark@463b2159{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
20/12/10 08:11:56 INFO ui.SparkUI: Stopped Spark web UI at http://b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:40478
20/12/10 08:11:56 INFO spark.ContextCleaner: Cleaned accumulator 314
20/12/10 08:11:56 INFO spark.ContextCleaner: Cleaned accumulator 218
20/12/10 08:11:56 INFO spark.ContextCleaner: Cleaned accumulator 284
20/12/10 08:11:56 INFO spark.ContextCleaner: Cleaned accumulator 300
20/12/10 08:11:56 INFO spark.ContextCleaner: Cleaned accumulator 329
20/12/10 08:11:56 INFO spark.ContextCleaner: Cleaned accumulator 335
20/12/10 08:11:56 INFO spark.ContextCleaner: Cleaned accumulator 370
20/12/10 08:11:56 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:38827 in memory (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:11:56 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795 in memory (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:11:56 INFO cluster.YarnClusterSchedulerBackend: Shutting down all executors
20/12/10 08:11:56 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/12/10 08:11:56 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
20/12/10 08:11:56 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/12/10 08:11:56 INFO memory.MemoryStore: MemoryStore cleared
20/12/10 08:11:56 INFO storage.BlockManager: BlockManager stopped
20/12/10 08:11:56 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
20/12/10 08:11:56 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/12/10 08:11:56 INFO spark.SparkContext: Successfully stopped SparkContext
20/12/10 08:11:56 INFO util.ShutdownHookManager: Shutdown hook called
20/12/10 08:11:56 INFO util.ShutdownHookManager: Deleting directory /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/spark-8eaeeb7b-8249-4428-906e-c29028451bfb
20/12/10 08:11:56 INFO util.ShutdownHookManager: Deleting directory /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/spark-8eaeeb7b-8249-4428-906e-c29028451bfb/pyspark-f877243f-a5e9-4e51-94ae-7de9fb9c80b3

End of LogType:stderr
***********************************************************************

Container: container_1606160497897_0548_01_000001 on b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud_8041
LogAggregationType: AGGREGATED
=======================================================================================================================
LogType:stdout
LogLastModifiedTime:Thu Dec 10 08:12:35 +0000 2020
LogLength:301
LogContents:
Traceback (most recent call last):
  File "load_data_into_hive.py", line 87, in <module>
    main()
  File "load_data_into_hive.py", line 79, in main
    df_artist_up = get_top_artist_from_top_playlist(log,df_artists_releases_full).coalesce()
TypeError: coalesce() takes exactly 2 arguments (1 given)

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_1606160497897_0548_02_000001 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud_8041
LogAggregationType: AGGREGATED
=======================================================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Thu Dec 10 08:12:36 +0000 2020
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_1606160497897_0548_02_000001 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud_8041
LogAggregationType: AGGREGATED
=======================================================================================================================
LogType:stderr
LogLastModifiedTime:Thu Dec 10 08:12:36 +0000 2020
LogLength:114340
LogContents:
20/12/10 08:11:58 INFO util.SignalUtils: Registered signal handler for TERM
20/12/10 08:11:58 INFO util.SignalUtils: Registered signal handler for HUP
20/12/10 08:11:58 INFO util.SignalUtils: Registered signal handler for INT
20/12/10 08:11:58 INFO spark.SecurityManager: Changing view acls to: yarn,iabd2_group6
20/12/10 08:11:58 INFO spark.SecurityManager: Changing modify acls to: yarn,iabd2_group6
20/12/10 08:11:58 INFO spark.SecurityManager: Changing view acls groups to: 
20/12/10 08:11:58 INFO spark.SecurityManager: Changing modify acls groups to: 
20/12/10 08:11:58 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, iabd2_group6); groups with view permissions: Set(); users  with modify permissions: Set(yarn, iabd2_group6); groups with modify permissions: Set()
20/12/10 08:11:59 INFO yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1606160497897_0548_000002
20/12/10 08:11:59 INFO yarn.ApplicationMaster: Starting the user application in a separate Thread
20/12/10 08:11:59 INFO yarn.ApplicationMaster: Waiting for spark context initialization...
20/12/10 08:11:59 INFO spark.SparkContext: Running Spark version 2.4.0-cdh6.3.2
20/12/10 08:11:59 INFO spark.SparkContext: Submitted application: collect_data
20/12/10 08:12:00 INFO spark.SecurityManager: Changing view acls to: yarn,iabd2_group6
20/12/10 08:12:00 INFO spark.SecurityManager: Changing modify acls to: yarn,iabd2_group6
20/12/10 08:12:00 INFO spark.SecurityManager: Changing view acls groups to: 
20/12/10 08:12:00 INFO spark.SecurityManager: Changing modify acls groups to: 
20/12/10 08:12:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, iabd2_group6); groups with view permissions: Set(); users  with modify permissions: Set(yarn, iabd2_group6); groups with modify permissions: Set()
20/12/10 08:12:00 INFO util.Utils: Successfully started service 'sparkDriver' on port 35121.
20/12/10 08:12:00 INFO spark.SparkEnv: Registering MapOutputTracker
20/12/10 08:12:00 INFO spark.SparkEnv: Registering BlockManagerMaster
20/12/10 08:12:00 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/12/10 08:12:00 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/12/10 08:12:00 INFO storage.DiskBlockManager: Created local directory at /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/blockmgr-bbd5027d-cfc3-4a75-a2cd-7a89514a9512
20/12/10 08:12:00 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB
20/12/10 08:12:00 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/12/10 08:12:00 INFO util.log: Logging initialized @4076ms
20/12/10 08:12:01 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
20/12/10 08:12:01 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: 2018-09-04T21:11:46Z, git hash: 3ce520221d0240229c862b122d2b06c12a625732
20/12/10 08:12:01 INFO server.Server: Started @4216ms
20/12/10 08:12:01 INFO server.AbstractConnector: Started ServerConnector@6811484d{HTTP/1.1,[http/1.1]}{0.0.0.0:45792}
20/12/10 08:12:01 INFO util.Utils: Successfully started service 'SparkUI' on port 45792.
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1efa57b9{/jobs,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7fb2cc90{/jobs/json,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4f47d0b7{/jobs/job,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1497d2aa{/jobs/job/json,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7d285ae4{/stages,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c1bef9e{/stages/json,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3705162d{/stages/stage,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@71d96a12{/stages/stage/json,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef2be7a{/stages/pool,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f2931e9{/stages/pool/json,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@55b81f34{/storage,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f0b766b{/storage/json,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@14f1049e{/storage/rdd,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4281d990{/storage/rdd/json,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@57d53f4b{/environment,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@63d9b3f4{/environment/json,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f909ee5{/executors,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@331195de{/executors/json,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4d40db90{/executors/threadDump,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@63a887df{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@18b44af9{/static,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@64874b51{/,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@306dcae7{/api,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@a1756a9{/jobs/job/kill,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a8dfef9{/stages/stage/kill,null,AVAILABLE,@Spark}
20/12/10 08:12:01 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:45792
20/12/10 08:12:01 INFO cluster.YarnClusterScheduler: Created YarnClusterScheduler
20/12/10 08:12:01 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:01 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/12/10 08:12:01 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1606160497897_0548 and attemptId Some(appattempt_1606160497897_0548_000002)
20/12/10 08:12:01 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44654.
20/12/10 08:12:01 INFO netty.NettyBlockTransferService: Server created on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654
20/12/10 08:12:01 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/12/10 08:12:01 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, 44654, None)
20/12/10 08:12:01 INFO storage.BlockManagerMasterEndpoint: Registering block manager da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 with 366.3 MB RAM, BlockManagerId(driver, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, 44654, None)
20/12/10 08:12:01 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, 44654, None)
20/12/10 08:12:01 INFO storage.BlockManager: external shuffle service port = 7337
20/12/10 08:12:01 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, 44654, None)
20/12/10 08:12:01 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
20/12/10 08:12:01 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@be99b03{/metrics/json,null,AVAILABLE,@Spark}
20/12/10 08:12:02 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:03 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:03 INFO scheduler.EventLoggingListener: Logging events to hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/spark/applicationHistory/application_1606160497897_0548_2
20/12/10 08:12:03 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/12/10 08:12:03 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
20/12/10 08:12:03 INFO spark.SparkContext: Registered listener com.cloudera.spark.lineage.NavigatorAppListener
20/12/10 08:12:03 INFO client.RMProxy: Connecting to ResourceManager at d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud/10.66.41.193:8030
20/12/10 08:12:03 INFO yarn.YarnRMClient: Registering the ApplicationMaster
20/12/10 08:12:04 INFO yarn.ApplicationMaster: Preparing Local resources
20/12/10 08:12:04 INFO yarn.ApplicationMaster: 
===============================================================================
YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/jars/*<CPS>{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/hive/*<CPS>$HADOOP_CLIENT_CONF_DIR<CPS>$HADOOP_COMMON_HOME/*<CPS>$HADOOP_COMMON_HOME/lib/*<CPS>$HADOOP_HDFS_HOME/*<CPS>$HADOOP_HDFS_HOME/lib/*<CPS>$HADOOP_YARN_HOME/*<CPS>$HADOOP_YARN_HOME/lib/*<CPS>$HADOOP_CLIENT_CONF_DIR<CPS>$PWD/mr-framework/*<CPS>$MR2_CLASSPATH<CPS>{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/accessors-smart-1.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/accessors-smart.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/asm-5.0.4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/asm.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/avro.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/aws-java-sdk-bundle-1.11.271.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/aws-java-sdk-bundle.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/azure-data-lake-store-sdk-2.2.9.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/azure-data-lake-store-sdk.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-beanutils-1.9.4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-beanutils.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-cli-1.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-cli.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-codec-1.11.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-codec.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-collections-3.2.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-collections.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-compress-1.18.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-compress.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-configuration2-2.1.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-configuration2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-io-2.6.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-io.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang-2.6.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang3-3.7.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-logging-1.1.3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-logging.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-math3-3.1.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-math3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-net-3.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-net.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-client-2.12.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-client.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-framework-2.12.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-framework.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-recipes-2.12.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-recipes.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/gson-2.2.4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/gson.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/guava-11.0.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/guava.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-annotations-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-annotations.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-auth-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-auth.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-aws-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-aws.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-datalake-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-datalake.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-common-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-common.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-hdfs-client-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-hdfs-client.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-common-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-common.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-core-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-core.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-jobclient-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-jobclient.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-api-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-client-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-client.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-common-3.0.0-cdh6.3.2.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-common.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/htrace-core4-4.1.0-incubating.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/htrace-core4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpclient-4.5.3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpclient.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpcore-4.4.6.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpcore.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/javax.activation-api-1.2.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/javax.activation-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jaxb-api-2.2.11.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jaxb-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jcip-annotations-1.0-1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jcip-annotations.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/json-smart-2.3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/json-smart.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsp-api-2.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsp-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr305-3.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr305.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr311-api-1.1.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr311-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-admin-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-admin.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-client-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-client.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-common-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-common.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-core-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-core.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-crypto-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-crypto.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-identity-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-identity.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-server-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-server.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-simplekdc-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-simplekdc.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-util-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-util.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-asn1-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-asn1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-config-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-config.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-pkix-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-pkix.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-util-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-util.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-xdr-1.0.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-xdr.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/log4j-1.2.17.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/log4j.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/nimbus-jose-jwt-4.41.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/nimbus-jose-jwt.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okhttp-2.7.5.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okhttp.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okio-1.6.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okio.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/paranamer-2.8.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/paranamer.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/protobuf-java-2.5.0.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/protobuf-java.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/re2j-1.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/re2j.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/snappy-java-1.1.4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/snappy-java.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/stax2-api-3.1.4.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/stax2-api.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/wildfly-openssl-1.0.4.Final.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/wildfly-openssl.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/woodstox-core-5.0.3.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/woodstox-core.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/xz-1.6.jar:{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/xz.jar<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    MKL_NUM_THREADS -> 1
    SPARK_DIST_CLASSPATH -> /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/accessors-smart-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/accessors-smart.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/asm-5.0.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/asm.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/avro.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/aws-java-sdk-bundle-1.11.271.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/aws-java-sdk-bundle.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/azure-data-lake-store-sdk-2.2.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/azure-data-lake-store-sdk.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-beanutils-1.9.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-beanutils.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-cli.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-codec-1.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-codec.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-collections.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-compress-1.18.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-compress.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-configuration2-2.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-configuration2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-io-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-io.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang3-3.7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-lang3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-logging.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-math3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/commons-net.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-client-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-framework-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-framework.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-recipes-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/curator-recipes.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/gson.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/guava.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-annotations-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-annotations.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-auth-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-auth.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-aws-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-aws.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-datalake-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure-datalake.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-azure.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-hdfs-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-hdfs-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-core-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-core.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-jobclient-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-mapreduce-client-jobclient.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-api-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/htrace-core4-4.1.0-incubating.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/htrace-core4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpclient-4.5.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpclient.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpcore-4.4.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/httpcore.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/javax.activation-api-1.2.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/javax.activation-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jaxb-api-2.2.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jaxb-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jcip-annotations-1.0-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jcip-annotations.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/json-smart-2.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/json-smart.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsp-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr305.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr311-api-1.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/jsr311-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-admin-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-admin.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-client-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-common-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-core-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-core.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-crypto-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-crypto.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-identity-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-identity.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-server-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-server.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-simplekdc-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-simplekdc.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerb-util.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-asn1-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-asn1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-config-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-config.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-pkix-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-pkix.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-util.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-xdr-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/kerby-xdr.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/log4j.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/nimbus-jose-jwt-4.41.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/nimbus-jose-jwt.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okhttp-2.7.5.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okhttp.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okio-1.6.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/okio.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/paranamer-2.8.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/paranamer.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/protobuf-java.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/re2j-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/re2j.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/snappy-java-1.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/snappy-java.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/stax2-api-3.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/stax2-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/wildfly-openssl-1.0.4.Final.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/wildfly-openssl.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/woodstox-core-5.0.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/woodstox-core.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/xz-1.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/client/xz.jar
    SPARK_YARN_STAGING_DIR -> hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/.sparkStaging/application_1606160497897_0548
    SPARK_USER -> iabd2_group6
    PYTHONPATH -> /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/python/lib/py4j-0.10.7-src.zip<CPS>/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/spark/python/lib/pyspark.zip
    OPENBLAS_NUM_THREADS -> 1

  command:
    LD_LIBRARY_PATH=\"{{HADOOP_COMMON_HOME}}/../../../CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/native:$LD_LIBRARY_PATH\" \ 
      {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx1024m \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.authenticate=false' \ 
      '-Dspark.driver.port=35121' \ 
      '-Dspark.network.crypto.enabled=false' \ 
      '-Dspark.shuffle.service.port=7337' \ 
      '-Dspark.ui.port=0' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.CoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:35121 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      1 \ 
      --app-id \ 
      application_1606160497897_0548 \ 
      --user-class-path \ 
      file:$PWD/__app__.jar \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    __spark_conf__ -> resource { scheme: "hdfs" host: "d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud" port: 8020 file: "/user/iabd2_group6/.sparkStaging/application_1606160497897_0548/__spark_conf__.zip" } size: 163520 timestamp: 1607587891930 type: ARCHIVE visibility: PRIVATE

===============================================================================
20/12/10 08:12:04 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
20/12/10 08:12:04 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:04 INFO conf.Configuration: resource-types.xml not found
20/12/10 08:12:04 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
20/12/10 08:12:04 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:35121)
20/12/10 08:12:04 INFO yarn.ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
20/12/10 08:12:04 INFO cluster.YarnClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
20/12/10 08:12:04 INFO cluster.YarnClusterScheduler: YarnClusterScheduler.postStartHook done
20/12/10 08:12:04 INFO internal.SharedState: loading hive config file: file:/yarn/nm/usercache/iabd2_group6/filecache/81/__spark_conf__.zip/__hadoop_conf__/hive-site.xml
20/12/10 08:12:04 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('/user/hive/warehouse') to the value of spark.sql.warehouse.dir ('hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/hive/warehouse/').
20/12/10 08:12:04 INFO internal.SharedState: Warehouse path is 'hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/hive/warehouse/'.
20/12/10 08:12:04 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.
20/12/10 08:12:04 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5164f3e1{/SQL,null,AVAILABLE,@Spark}
20/12/10 08:12:04 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.
20/12/10 08:12:04 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2868f542{/SQL/json,null,AVAILABLE,@Spark}
20/12/10 08:12:04 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.
20/12/10 08:12:04 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7b8ce0f2{/SQL/execution,null,AVAILABLE,@Spark}
20/12/10 08:12:04 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.
20/12/10 08:12:04 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@297ff58a{/SQL/execution/json,null,AVAILABLE,@Spark}
20/12/10 08:12:04 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.
20/12/10 08:12:04 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@335e63f0{/static/sql,null,AVAILABLE,@Spark}
20/12/10 08:12:05 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:05 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
20/12/10 08:12:05 INFO __main__: pyspark script logger initialized
20/12/10 08:12:06 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:07 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:08 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:08 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:09 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
20/12/10 08:12:09 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:09 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:09 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:09 INFO codegen.CodeGenerator: Code generated in 430.157307 ms
20/12/10 08:12:09 INFO codegen.CodeGenerator: Code generated in 32.042948 ms
20/12/10 08:12:10 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 473.6 KB, free 365.8 MB)
20/12/10 08:12:10 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:10 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 49.8 KB, free 365.8 MB)
20/12/10 08:12:10 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 366.3 MB)
20/12/10 08:12:10 INFO spark.SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:10 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:10 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:10 INFO scheduler.DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:10 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:10 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:10 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:10 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:10 INFO yarn.YarnAllocator: Driver requested a total number of 1 executor(s).
20/12/10 08:12:10 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)
20/12/10 08:12:10 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 1 core(s) and 1408 MB memory (including 384 MB of overhead)
20/12/10 08:12:10 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 365.8 MB)
20/12/10 08:12:10 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 365.8 MB)
20/12/10 08:12:10 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 4.5 KB, free: 366.2 MB)
20/12/10 08:12:10 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:10 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:10 INFO cluster.YarnClusterScheduler: Adding task set 0.0 with 1 tasks
20/12/10 08:12:11 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:11 INFO yarn.YarnAllocator: Submitted container request for host bab6e83c-2a27-42b6-b0f0-b66263e83587.priv.instances.scw.cloud,b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud,e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud.
20/12/10 08:12:11 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:11 INFO yarn.YarnAllocator: Launching container container_1606160497897_0548_02_000002 on host da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud for executor with ID 1
20/12/10 08:12:11 INFO yarn.YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
20/12/10 08:12:12 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:13 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:14 INFO yarn.SparkRackResolver: Got an error when resolving hostNames. Falling back to /default-rack for all
20/12/10 08:12:14 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.69.120.29:54124) with ID 1
20/12/10 08:12:14 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1)
20/12/10 08:12:14 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, RACK_LOCAL, 8400 bytes)
20/12/10 08:12:15 INFO storage.BlockManagerMasterEndpoint: Registering block manager da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 with 366.3 MB RAM, BlockManagerId(1, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, 41833, None)
20/12/10 08:12:15 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 4.5 KB, free: 366.3 MB)
20/12/10 08:12:16 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 366.2 MB)
20/12/10 08:12:18 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3667 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:18 INFO cluster.YarnClusterScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/12/10 08:12:18 INFO yarn.YarnAllocator: Driver requested a total number of 0 executor(s).
20/12/10 08:12:18 INFO scheduler.DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 7.610 s
20/12/10 08:12:18 INFO scheduler.DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 7.745009 s
20/12/10 08:12:18 INFO conf.HiveConf: Found configuration file file:/yarn/nm/usercache/iabd2_group6/filecache/81/__spark_conf__.zip/__hadoop_conf__/hive-site.xml
20/12/10 08:12:18 INFO hive.HiveUtils: Initializing HiveMetastoreConnection version 2.1 using Spark classes.
20/12/10 08:12:18 INFO spark.ContextCleaner: Cleaned accumulator 23
20/12/10 08:12:19 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 4.5 KB, free: 366.3 MB)
20/12/10 08:12:19 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 4.5 KB, free: 366.3 MB)
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 15
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 22
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 16
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 24
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 11
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 13
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 19
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 18
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 10
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 21
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 20
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 7
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 31
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 26
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 30
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 29
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 14
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 27
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 9
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 28
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 32
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 12
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 8
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 25
20/12/10 08:12:19 INFO spark.ContextCleaner: Cleaned accumulator 17
20/12/10 08:12:19 INFO conf.HiveConf: Found configuration file file:/yarn/nm/usercache/iabd2_group6/filecache/81/__spark_conf__.zip/__hadoop_conf__/hive-site.xml
20/12/10 08:12:19 INFO session.SessionState: Created local directory: /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/container_1606160497897_0548_02_000001/tmp/yarn
20/12/10 08:12:19 INFO session.SessionState: Created HDFS directory: /tmp/hive/iabd2_group6/d876688e-a11d-4e63-9fe7-ae37fc9a5a51
20/12/10 08:12:19 INFO session.SessionState: Created local directory: /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/container_1606160497897_0548_02_000001/tmp/yarn/d876688e-a11d-4e63-9fe7-ae37fc9a5a51
20/12/10 08:12:19 INFO session.SessionState: Created HDFS directory: /tmp/hive/iabd2_group6/d876688e-a11d-4e63-9fe7-ae37fc9a5a51/_tmp_space.db
20/12/10 08:12:19 INFO client.HiveClientImpl: Warehouse location for Hive client (version 2.1.1) is hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/hive/warehouse/
20/12/10 08:12:20 INFO hive.metastore: HMS client filtering is enabled.
20/12/10 08:12:20 INFO hive.metastore: Trying to connect to metastore with URI thrift://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:9083
20/12/10 08:12:20 INFO hive.metastore: Opened a connection to metastore, current connections: 1
20/12/10 08:12:20 INFO hive.metastore: Connected to metastore.
20/12/10 08:12:21 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:21 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:12:21 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:21 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:21 INFO codegen.CodeGenerator: Code generated in 12.060848 ms
20/12/10 08:12:21 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 473.6 KB, free 365.3 MB)
20/12/10 08:12:21 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 49.8 KB, free 365.3 MB)
20/12/10 08:12:21 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 366.2 MB)
20/12/10 08:12:21 INFO spark.SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:21 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:21 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:21 INFO scheduler.DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:21 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:21 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:21 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:21 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:21 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.3 KB, free 365.3 MB)
20/12/10 08:12:21 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.1 KB, free 365.3 MB)
20/12/10 08:12:21 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 7.1 KB, free: 366.2 MB)
20/12/10 08:12:21 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:21 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:21 INFO cluster.YarnClusterScheduler: Adding task set 1.0 with 1 tasks
20/12/10 08:12:21 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, RACK_LOCAL, 8400 bytes)
20/12/10 08:12:21 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 7.1 KB, free: 366.2 MB)
20/12/10 08:12:23 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 366.2 MB)
20/12/10 08:12:23 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2113 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:23 INFO cluster.YarnClusterScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/12/10 08:12:23 INFO scheduler.DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 2.140 s
20/12/10 08:12:23 INFO scheduler.DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 2.150020 s
20/12/10 08:12:23 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_albums_releases_full.csv ... OK
20/12/10 08:12:23 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:23 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#50, None)) > 0)
20/12/10 08:12:23 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:23 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:23 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 473.6 KB, free 364.8 MB)
20/12/10 08:12:23 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 49.8 KB, free 364.7 MB)
20/12/10 08:12:23 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 366.1 MB)
20/12/10 08:12:23 INFO spark.SparkContext: Created broadcast 4 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:23 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:23 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:23 INFO scheduler.DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:23 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:23 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:23 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:23 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.8 KB, free 364.7 MB)
20/12/10 08:12:23 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 364.7 MB)
20/12/10 08:12:23 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 4.5 KB, free: 366.1 MB)
20/12/10 08:12:23 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:23 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:23 INFO cluster.YarnClusterScheduler: Adding task set 2.0 with 1 tasks
20/12/10 08:12:23 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8401 bytes)
20/12/10 08:12:23 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 4.5 KB, free: 366.2 MB)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 366.1 MB)
20/12/10 08:12:24 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 125 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:24 INFO cluster.YarnClusterScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/12/10 08:12:24 INFO scheduler.DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.142 s
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.153091 s
20/12/10 08:12:24 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:24 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:12:24 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:24 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 473.6 KB, free 364.3 MB)
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 49.8 KB, free 364.2 MB)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 366.1 MB)
20/12/10 08:12:24 INFO spark.SparkContext: Created broadcast 6 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:24 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:24 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.2 KB, free 364.2 MB)
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.1 KB, free 364.2 MB)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 7.1 KB, free: 366.1 MB)
20/12/10 08:12:24 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:24 INFO cluster.YarnClusterScheduler: Adding task set 3.0 with 1 tasks
20/12/10 08:12:24 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8401 bytes)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 7.1 KB, free: 366.1 MB)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 366.1 MB)
20/12/10 08:12:24 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 153 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:24 INFO cluster.YarnClusterScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/12/10 08:12:24 INFO scheduler.DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.175 s
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.178332 s
20/12/10 08:12:24 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_artists_releases_full.csv ... OK
20/12/10 08:12:24 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:24 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#82, None)) > 0)
20/12/10 08:12:24 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:24 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 473.6 KB, free 363.7 MB)
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 49.8 KB, free 363.7 MB)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 366.0 MB)
20/12/10 08:12:24 INFO spark.SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:24 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:24 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Got job 4 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 8.8 KB, free 363.7 MB)
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.5 KB, free 363.7 MB)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 4.5 KB, free: 366.0 MB)
20/12/10 08:12:24 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:24 INFO cluster.YarnClusterScheduler: Adding task set 4.0 with 1 tasks
20/12/10 08:12:24 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8400 bytes)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 4.5 KB, free: 366.1 MB)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 366.0 MB)
20/12/10 08:12:24 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 110 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:24 INFO cluster.YarnClusterScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/12/10 08:12:24 INFO scheduler.DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0) finished in 0.129 s
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Job 4 finished: csv at NativeMethodAccessorImpl.java:0, took 0.135094 s
20/12/10 08:12:24 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:24 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:12:24 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:24 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 473.6 KB, free 363.2 MB)
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 49.8 KB, free 363.2 MB)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 366.0 MB)
20/12/10 08:12:24 INFO spark.SparkContext: Created broadcast 10 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:24 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:24 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Got job 5 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.3 KB, free 363.2 MB)
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.1 KB, free 363.1 MB)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 7.1 KB, free: 366.0 MB)
20/12/10 08:12:24 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:24 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:24 INFO cluster.YarnClusterScheduler: Adding task set 5.0 with 1 tasks
20/12/10 08:12:24 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8400 bytes)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 7.1 KB, free: 366.0 MB)
20/12/10 08:12:24 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 366.0 MB)
20/12/10 08:12:25 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 204 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:25 INFO cluster.YarnClusterScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/12/10 08:12:25 INFO scheduler.DAGScheduler: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0) finished in 0.223 s
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Job 5 finished: csv at NativeMethodAccessorImpl.java:0, took 0.227527 s
20/12/10 08:12:25 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_tracks_featured_full.csv ... OK
20/12/10 08:12:25 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:25 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#128, None)) > 0)
20/12/10 08:12:25 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:25 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 473.6 KB, free 362.7 MB)
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 49.8 KB, free 362.6 MB)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 365.9 MB)
20/12/10 08:12:25 INFO spark.SparkContext: Created broadcast 12 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:25 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:25 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[30] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.8 KB, free 362.6 MB)
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 362.6 MB)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 4.5 KB, free: 365.9 MB)
20/12/10 08:12:25 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[30] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:25 INFO cluster.YarnClusterScheduler: Adding task set 6.0 with 1 tasks
20/12/10 08:12:25 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, RACK_LOCAL, 8400 bytes)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 4.5 KB, free: 366.0 MB)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 365.9 MB)
20/12/10 08:12:25 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 104 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:25 INFO cluster.YarnClusterScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/12/10 08:12:25 INFO scheduler.DAGScheduler: ResultStage 6 (csv at NativeMethodAccessorImpl.java:0) finished in 0.117 s
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Job 6 finished: csv at NativeMethodAccessorImpl.java:0, took 0.122949 s
20/12/10 08:12:25 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:25 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:12:25 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:25 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 473.6 KB, free 362.2 MB)
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 49.8 KB, free 362.1 MB)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 365.9 MB)
20/12/10 08:12:25 INFO spark.SparkContext: Created broadcast 14 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:25 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:25 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Got job 7 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Final stage: ResultStage 7 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 13.3 KB, free 362.1 MB)
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.1 KB, free 362.1 MB)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 7.1 KB, free: 365.9 MB)
20/12/10 08:12:25 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:25 INFO cluster.YarnClusterScheduler: Adding task set 7.0 with 1 tasks
20/12/10 08:12:25 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, RACK_LOCAL, 8400 bytes)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 7.1 KB, free: 365.9 MB)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 365.9 MB)
20/12/10 08:12:25 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 186 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:25 INFO cluster.YarnClusterScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/12/10 08:12:25 INFO scheduler.DAGScheduler: ResultStage 7 (csv at NativeMethodAccessorImpl.java:0) finished in 0.206 s
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Job 7 finished: csv at NativeMethodAccessorImpl.java:0, took 0.212950 s
20/12/10 08:12:25 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_tracks_releases_full.csv ... OK
20/12/10 08:12:25 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:25 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#174, None)) > 0)
20/12/10 08:12:25 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:25 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 473.6 KB, free 361.6 MB)
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 49.8 KB, free 361.6 MB)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:12:25 INFO spark.SparkContext: Created broadcast 16 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:25 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:25 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Got job 8 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 8.8 KB, free 361.6 MB)
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.5 KB, free 361.6 MB)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 4.5 KB, free: 365.8 MB)
20/12/10 08:12:25 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:25 INFO cluster.YarnClusterScheduler: Adding task set 8.0 with 1 tasks
20/12/10 08:12:25 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8403 bytes)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 4.5 KB, free: 365.9 MB)
20/12/10 08:12:25 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:12:25 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 101 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:25 INFO cluster.YarnClusterScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/12/10 08:12:25 INFO scheduler.DAGScheduler: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0) finished in 0.113 s
20/12/10 08:12:25 INFO scheduler.DAGScheduler: Job 8 finished: csv at NativeMethodAccessorImpl.java:0, took 0.116656 s
20/12/10 08:12:26 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:26 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:12:26 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:26 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 473.6 KB, free 361.1 MB)
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 49.8 KB, free 361.1 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO spark.SparkContext: Created broadcast 18 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:26 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:26 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Got job 9 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 9 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[44] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 13.2 KB, free 361.0 MB)
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.1 KB, free 361.0 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 7.1 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[44] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:26 INFO cluster.YarnClusterScheduler: Adding task set 9.0 with 1 tasks
20/12/10 08:12:26 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8403 bytes)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 7.1 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 147 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:26 INFO cluster.YarnClusterScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/12/10 08:12:26 INFO scheduler.DAGScheduler: ResultStage 9 (csv at NativeMethodAccessorImpl.java:0) finished in 0.164 s
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Job 9 finished: csv at NativeMethodAccessorImpl.java:0, took 0.168899 s
20/12/10 08:12:26 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_playlists_featured_full.csv ... OK
20/12/10 08:12:26 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:26 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#216, None)) > 0)
20/12/10 08:12:26 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:26 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 473.6 KB, free 360.6 MB)
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 49.8 KB, free 360.5 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO spark.SparkContext: Created broadcast 20 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:26 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:26 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Got job 10 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[48] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 8.8 KB, free 360.5 MB)
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.5 KB, free 360.5 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 4.5 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[48] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:26 INFO cluster.YarnClusterScheduler: Adding task set 10.0 with 1 tasks
20/12/10 08:12:26 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8401 bytes)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 4.5 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 104 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:26 INFO cluster.YarnClusterScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/12/10 08:12:26 INFO scheduler.DAGScheduler: ResultStage 10 (csv at NativeMethodAccessorImpl.java:0) finished in 0.122 s
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Job 10 finished: csv at NativeMethodAccessorImpl.java:0, took 0.129049 s
20/12/10 08:12:26 INFO datasources.FileSourceStrategy: Pruning directories with: 
20/12/10 08:12:26 INFO datasources.FileSourceStrategy: Post-Scan Filters: 
20/12/10 08:12:26 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
20/12/10 08:12:26 INFO execution.FileSourceScanExec: Pushed Filters: 
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 473.6 KB, free 360.1 MB)
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 273
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 264
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 39
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 84
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 262
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 250
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 91
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 304
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 204
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 278
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 154
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 168
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 232
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 214
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 114
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 73
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 225
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 210
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 251
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 103
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 303
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 242
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 44
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 131
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 328
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 340
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 223
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 290
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 78
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 316
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 7.1 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 7.1 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 85
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 279
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 7.1 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 7.1 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 49.8 KB, free 360.0 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 49.8 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO spark.SparkContext: Created broadcast 22 from csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:26 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 239
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 337
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 297
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 144
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 180
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 227
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 155
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 342
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 169
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 133
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 109
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 142
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 203
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 190
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 68
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 327
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 122
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 147
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 146
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 94
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 206
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 284
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 285
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 271
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 325
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 318
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 99
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 270
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 82
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 159
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 275
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 185
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 60
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 57
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 292
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 4.5 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 4.5 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 170
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 183
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Got job 11 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 11 (csv at NativeMethodAccessorImpl.java:0)
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Missing parents: List()
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[53] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 49.8 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 13.2 KB, free 360.1 MB)
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.1 KB, free 360.5 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 (size: 7.1 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1164
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[53] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
20/12/10 08:12:26 INFO cluster.YarnClusterScheduler: Adding task set 11.0 with 1 tasks
20/12/10 08:12:26 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, executor 1, partition 0, NODE_LOCAL, 8401 bytes)
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 266
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 129
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 265
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 320
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 125
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 83
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 236
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 202
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 317
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 52
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 98
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 305
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 139
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 51
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 164
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 136
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 309
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 86
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 124
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 347
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 268
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 313
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 274
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 245
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 199
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 263
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 269
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 181
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 218
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 141
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 298
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 72
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 102
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 213
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 287
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 344
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 172
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 135
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 281
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 157
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 74
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 153
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 138
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 137
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 56
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 299
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 46
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 4.5 KB, free: 365.7 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 4.5 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 7.1 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 63
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 45
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 152
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 306
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 289
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 212
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 7.1 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 7.1 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 294
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 288
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 209
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 335
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 260
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 334
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 105
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 339
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 110
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 343
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 64
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 111
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 70
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 101
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 258
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 322
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 4.5 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 4.5 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 166 ms on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud (executor 1) (1/1)
20/12/10 08:12:26 INFO cluster.YarnClusterScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/12/10 08:12:26 INFO scheduler.DAGScheduler: ResultStage 11 (csv at NativeMethodAccessorImpl.java:0) finished in 0.186 s
20/12/10 08:12:26 INFO scheduler.DAGScheduler: Job 11 finished: csv at NativeMethodAccessorImpl.java:0, took 0.190591 s
20/12/10 08:12:26 INFO __main__: load de la table /user/iabd2_group6/data/20201210/df_artists_featured_full.csv ... OK
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 158
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 293
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 197
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 321
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 67
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 301
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 108
20/12/10 08:12:26 INFO spark.ContextCleaner: Cleaned accumulator 283
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:12:26 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 49.8 KB, free: 365.8 MB)
20/12/10 08:12:27 INFO __main__: get_top_artist_from_top_playlist .. ok
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 184
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 323
20/12/10 08:12:27 ERROR yarn.ApplicationMaster: User application exited with status 1
20/12/10 08:12:27 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 1, (reason: User application exited with status 1)
20/12/10 08:12:27 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 7.1 KB, free: 365.8 MB)
20/12/10 08:12:27 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 7.1 KB, free: 365.8 MB)
20/12/10 08:12:27 INFO spark.SparkContext: Invoking stop() from shutdown hook
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 198
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 326
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 240
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 59
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 160
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 89
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 244
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 220
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 134
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 217
20/12/10 08:12:27 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 7.1 KB, free: 365.8 MB)
20/12/10 08:12:27 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 7.1 KB, free: 365.8 MB)
20/12/10 08:12:27 INFO server.AbstractConnector: Stopped Spark@6811484d{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 295
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 49
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 48
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 257
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 79
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 254
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 162
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 130
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 249
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 113
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 194
20/12/10 08:12:27 INFO spark.ContextCleaner: Cleaned accumulator 92
20/12/10 08:12:27 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833 in memory (size: 49.8 KB, free: 365.9 MB)
20/12/10 08:12:27 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:44654 in memory (size: 49.8 KB, free: 365.9 MB)
20/12/10 08:12:27 INFO ui.SparkUI: Stopped Spark web UI at http://da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:45792
20/12/10 08:12:27 INFO cluster.YarnClusterSchedulerBackend: Shutting down all executors
20/12/10 08:12:27 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
20/12/10 08:12:27 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
20/12/10 08:12:27 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/12/10 08:12:27 INFO memory.MemoryStore: MemoryStore cleared
20/12/10 08:12:27 INFO storage.BlockManager: BlockManager stopped
20/12/10 08:12:27 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
20/12/10 08:12:27 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/12/10 08:12:27 INFO spark.SparkContext: Successfully stopped SparkContext
20/12/10 08:12:27 INFO yarn.ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: User application exited with status 1)
20/12/10 08:12:27 INFO impl.AMRMClientImpl: Waiting for application to be successfully unregistered.
20/12/10 08:12:27 INFO yarn.ApplicationMaster: Deleting staging directory hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/.sparkStaging/application_1606160497897_0548
20/12/10 08:12:27 INFO util.ShutdownHookManager: Shutdown hook called
20/12/10 08:12:27 INFO util.ShutdownHookManager: Deleting directory /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/spark-ac5fedb2-ca57-4a80-a773-fbc168e61333
20/12/10 08:12:27 INFO util.ShutdownHookManager: Deleting directory /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/spark-ac5fedb2-ca57-4a80-a773-fbc168e61333/pyspark-cfcb3635-9584-4aa5-8135-09fccea7334c

End of LogType:stderr
***********************************************************************

Container: container_1606160497897_0548_02_000001 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud_8041
LogAggregationType: AGGREGATED
=======================================================================================================================
LogType:stdout
LogLastModifiedTime:Thu Dec 10 08:12:36 +0000 2020
LogLength:301
LogContents:
Traceback (most recent call last):
  File "load_data_into_hive.py", line 87, in <module>
    main()
  File "load_data_into_hive.py", line 79, in main
    df_artist_up = get_top_artist_from_top_playlist(log,df_artists_releases_full).coalesce()
TypeError: coalesce() takes exactly 2 arguments (1 given)

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_1606160497897_0548_02_000002 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud_8041
LogAggregationType: AGGREGATED
=======================================================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Thu Dec 10 08:12:36 +0000 2020
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_1606160497897_0548_02_000002 on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud_8041
LogAggregationType: AGGREGATED
=======================================================================================================================
LogType:stderr
LogLastModifiedTime:Thu Dec 10 08:12:36 +0000 2020
LogLength:21840
LogContents:
20/12/10 08:12:12 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 24450@da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud
20/12/10 08:12:12 INFO util.SignalUtils: Registered signal handler for TERM
20/12/10 08:12:12 INFO util.SignalUtils: Registered signal handler for HUP
20/12/10 08:12:12 INFO util.SignalUtils: Registered signal handler for INT
20/12/10 08:12:13 INFO spark.SecurityManager: Changing view acls to: yarn,iabd2_group6
20/12/10 08:12:13 INFO spark.SecurityManager: Changing modify acls to: yarn,iabd2_group6
20/12/10 08:12:13 INFO spark.SecurityManager: Changing view acls groups to: 
20/12/10 08:12:13 INFO spark.SecurityManager: Changing modify acls groups to: 
20/12/10 08:12:13 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, iabd2_group6); groups with view permissions: Set(); users  with modify permissions: Set(yarn, iabd2_group6); groups with modify permissions: Set()
20/12/10 08:12:13 INFO client.TransportClientFactory: Successfully created connection to da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud/10.69.120.29:35121 after 121 ms (0 ms spent in bootstraps)
20/12/10 08:12:14 INFO spark.SecurityManager: Changing view acls to: yarn,iabd2_group6
20/12/10 08:12:14 INFO spark.SecurityManager: Changing modify acls to: yarn,iabd2_group6
20/12/10 08:12:14 INFO spark.SecurityManager: Changing view acls groups to: 
20/12/10 08:12:14 INFO spark.SecurityManager: Changing modify acls groups to: 
20/12/10 08:12:14 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, iabd2_group6); groups with view permissions: Set(); users  with modify permissions: Set(yarn, iabd2_group6); groups with modify permissions: Set()
20/12/10 08:12:14 INFO client.TransportClientFactory: Successfully created connection to da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud/10.69.120.29:35121 after 2 ms (0 ms spent in bootstraps)
20/12/10 08:12:14 INFO storage.DiskBlockManager: Created local directory at /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/blockmgr-f97a251c-a4dd-41fe-88f3-0ad5cf6e4ea4
20/12/10 08:12:14 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB
20/12/10 08:12:14 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:35121
20/12/10 08:12:14 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/12/10 08:12:14 INFO executor.Executor: Starting executor ID 1 on host da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud
20/12/10 08:12:14 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41833.
20/12/10 08:12:14 INFO netty.NettyBlockTransferService: Server created on da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud:41833
20/12/10 08:12:14 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/12/10 08:12:14 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(1, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, 41833, None)
20/12/10 08:12:15 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(1, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, 41833, None)
20/12/10 08:12:15 INFO storage.BlockManager: external shuffle service port = 7337
20/12/10 08:12:15 INFO storage.BlockManager: Registering executor with local external shuffle service.
20/12/10 08:12:15 INFO client.TransportClientFactory: Successfully created connection to da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud/10.69.120.29:7337 after 3 ms (0 ms spent in bootstraps)
20/12/10 08:12:15 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(1, da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud, 41833, None)
20/12/10 08:12:15 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 0
20/12/10 08:12:15 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
20/12/10 08:12:15 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/12/10 08:12:15 INFO client.TransportClientFactory: Successfully created connection to da5d8c78-7a5f-4e83-8cd2-7f1844e550dd.priv.instances.scw.cloud/10.69.120.29:44654 after 5 ms (0 ms spent in bootstraps)
20/12/10 08:12:15 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 366.3 MB)
20/12/10 08:12:15 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 263 ms
20/12/10 08:12:15 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
20/12/10 08:12:16 INFO codegen.CodeGenerator: Code generated in 282.363276 ms
20/12/10 08:12:16 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_albums_releases_full.csv, range: 0-1152884, partition values: [empty row]
20/12/10 08:12:16 INFO codegen.CodeGenerator: Code generated in 20.86711 ms
20/12/10 08:12:16 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
20/12/10 08:12:16 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 49.8 KB, free 366.2 MB)
20/12/10 08:12:16 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 24 ms
20/12/10 08:12:16 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 709.6 KB, free 365.5 MB)
20/12/10 08:12:18 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 1485 bytes result sent to driver
20/12/10 08:12:21 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1
20/12/10 08:12:21 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)
20/12/10 08:12:21 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/12/10 08:12:21 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.1 KB, free 365.6 MB)
20/12/10 08:12:21 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 21 ms
20/12/10 08:12:21 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.3 KB, free 365.5 MB)
20/12/10 08:12:21 INFO codegen.CodeGenerator: Code generated in 9.80206 ms
20/12/10 08:12:23 INFO codegen.CodeGenerator: Code generated in 15.431712 ms
20/12/10 08:12:23 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_albums_releases_full.csv, range: 0-1152884, partition values: [empty row]
20/12/10 08:12:23 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
20/12/10 08:12:23 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 49.8 KB, free 365.5 MB)
20/12/10 08:12:23 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 23 ms
20/12/10 08:12:23 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 709.6 KB, free 364.8 MB)
20/12/10 08:12:23 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 1615 bytes result sent to driver
20/12/10 08:12:23 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2
20/12/10 08:12:23 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 2)
20/12/10 08:12:23 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/12/10 08:12:23 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 364.8 MB)
20/12/10 08:12:23 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 19 ms
20/12/10 08:12:23 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.8 KB, free 364.8 MB)
20/12/10 08:12:24 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_artists_releases_full.csv, range: 0-32339, partition values: [empty row]
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 49.8 KB, free 364.7 MB)
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 16 ms
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 709.6 KB, free 364.0 MB)
20/12/10 08:12:24 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 2). 1308 bytes result sent to driver
20/12/10 08:12:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3
20/12/10 08:12:24 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 3)
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.1 KB, free 364.0 MB)
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 16 ms
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.2 KB, free 364.0 MB)
20/12/10 08:12:24 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_artists_releases_full.csv, range: 0-32339, partition values: [empty row]
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 49.8 KB, free 364.0 MB)
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 25 ms
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 709.6 KB, free 363.3 MB)
20/12/10 08:12:24 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 3). 1545 bytes result sent to driver
20/12/10 08:12:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 4
20/12/10 08:12:24 INFO executor.Executor: Running task 0.0 in stage 4.0 (TID 4)
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 9
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.5 KB, free 363.3 MB)
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Reading broadcast variable 9 took 21 ms
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 8.8 KB, free 363.3 MB)
20/12/10 08:12:24 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_tracks_featured_full.csv, range: 0-1589492, partition values: [empty row]
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 8
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 49.8 KB, free 363.2 MB)
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Reading broadcast variable 8 took 23 ms
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 709.6 KB, free 362.5 MB)
20/12/10 08:12:24 INFO executor.Executor: Finished task 0.0 in stage 4.0 (TID 4). 1391 bytes result sent to driver
20/12/10 08:12:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 5
20/12/10 08:12:24 INFO executor.Executor: Running task 0.0 in stage 5.0 (TID 5)
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 11
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.1 KB, free 362.5 MB)
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Reading broadcast variable 11 took 29 ms
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.3 KB, free 362.5 MB)
20/12/10 08:12:24 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_tracks_featured_full.csv, range: 0-1589492, partition values: [empty row]
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 10
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 49.8 KB, free 362.5 MB)
20/12/10 08:12:24 INFO broadcast.TorrentBroadcast: Reading broadcast variable 10 took 22 ms
20/12/10 08:12:24 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 709.6 KB, free 361.8 MB)
20/12/10 08:12:25 INFO executor.Executor: Finished task 0.0 in stage 5.0 (TID 5). 1523 bytes result sent to driver
20/12/10 08:12:25 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 6
20/12/10 08:12:25 INFO executor.Executor: Running task 0.0 in stage 6.0 (TID 6)
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 13
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 361.8 MB)
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Reading broadcast variable 13 took 21 ms
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.8 KB, free 361.8 MB)
20/12/10 08:12:25 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_tracks_releases_full.csv, range: 0-2148020, partition values: [empty row]
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 12
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 49.8 KB, free 361.7 MB)
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Reading broadcast variable 12 took 16 ms
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 709.6 KB, free 361.0 MB)
20/12/10 08:12:25 INFO executor.Executor: Finished task 0.0 in stage 6.0 (TID 6). 1391 bytes result sent to driver
20/12/10 08:12:25 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 7
20/12/10 08:12:25 INFO executor.Executor: Running task 0.0 in stage 7.0 (TID 7)
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 15
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.1 KB, free 361.0 MB)
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Reading broadcast variable 15 took 19 ms
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 13.3 KB, free 361.0 MB)
20/12/10 08:12:25 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_tracks_releases_full.csv, range: 0-2148020, partition values: [empty row]
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 14
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 49.8 KB, free 360.9 MB)
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Reading broadcast variable 14 took 19 ms
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 709.6 KB, free 360.2 MB)
20/12/10 08:12:25 INFO executor.Executor: Finished task 0.0 in stage 7.0 (TID 7). 1523 bytes result sent to driver
20/12/10 08:12:25 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 8
20/12/10 08:12:25 INFO executor.Executor: Running task 0.0 in stage 8.0 (TID 8)
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 17
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.5 KB, free 360.2 MB)
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Reading broadcast variable 17 took 16 ms
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 8.8 KB, free 360.2 MB)
20/12/10 08:12:25 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_playlists_featured_full.csv, range: 0-1313591, partition values: [empty row]
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 16
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 49.8 KB, free 360.2 MB)
20/12/10 08:12:25 INFO broadcast.TorrentBroadcast: Reading broadcast variable 16 took 18 ms
20/12/10 08:12:25 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 709.6 KB, free 359.5 MB)
20/12/10 08:12:25 INFO executor.Executor: Finished task 0.0 in stage 8.0 (TID 8). 1407 bytes result sent to driver
20/12/10 08:12:26 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 9
20/12/10 08:12:26 INFO executor.Executor: Running task 0.0 in stage 9.0 (TID 9)
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 19
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.1 KB, free 359.5 MB)
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Reading broadcast variable 19 took 18 ms
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 13.2 KB, free 359.5 MB)
20/12/10 08:12:26 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_playlists_featured_full.csv, range: 0-1313591, partition values: [empty row]
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 18
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 49.8 KB, free 359.4 MB)
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Reading broadcast variable 18 took 20 ms
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 709.6 KB, free 358.7 MB)
20/12/10 08:12:26 INFO executor.Executor: Finished task 0.0 in stage 9.0 (TID 9). 1635 bytes result sent to driver
20/12/10 08:12:26 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 10
20/12/10 08:12:26 INFO executor.Executor: Running task 0.0 in stage 10.0 (TID 10)
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 21
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.5 KB, free 358.7 MB)
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Reading broadcast variable 21 took 22 ms
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 8.8 KB, free 358.7 MB)
20/12/10 08:12:26 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_artists_featured_full.csv, range: 0-316788, partition values: [empty row]
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 20
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 49.8 KB, free 358.7 MB)
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Reading broadcast variable 20 took 16 ms
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 709.6 KB, free 358.0 MB)
20/12/10 08:12:26 INFO executor.Executor: Finished task 0.0 in stage 10.0 (TID 10). 1308 bytes result sent to driver
20/12/10 08:12:26 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 11
20/12/10 08:12:26 INFO executor.Executor: Running task 0.0 in stage 11.0 (TID 11)
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 23
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.1 KB, free 358.8 MB)
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Reading broadcast variable 23 took 26 ms
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 13.2 KB, free 358.8 MB)
20/12/10 08:12:26 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_artists_featured_full.csv, range: 0-316788, partition values: [empty row]
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 22
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 49.8 KB, free 359.5 MB)
20/12/10 08:12:26 INFO broadcast.TorrentBroadcast: Reading broadcast variable 22 took 15 ms
20/12/10 08:12:26 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 709.6 KB, free 358.8 MB)
20/12/10 08:12:26 INFO executor.Executor: Finished task 0.0 in stage 11.0 (TID 11). 1545 bytes result sent to driver
20/12/10 08:12:27 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/12/10 08:12:27 INFO memory.MemoryStore: MemoryStore cleared
20/12/10 08:12:27 INFO storage.BlockManager: BlockManager stopped
20/12/10 08:12:27 INFO util.ShutdownHookManager: Shutdown hook called

End of LogType:stderr
***********************************************************************


End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_1606160497897_0548_01_000002 on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud_8041
LogAggregationType: AGGREGATED
=======================================================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Thu Dec 10 08:12:35 +0000 2020
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_1606160497897_0548_01_000002 on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud_8041
LogAggregationType: AGGREGATED
=======================================================================================================================
LogType:stderr
LogLastModifiedTime:Thu Dec 10 08:12:35 +0000 2020
LogLength:21843
LogContents:
20/12/10 08:11:41 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 31130@e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud
20/12/10 08:11:41 INFO util.SignalUtils: Registered signal handler for TERM
20/12/10 08:11:41 INFO util.SignalUtils: Registered signal handler for HUP
20/12/10 08:11:41 INFO util.SignalUtils: Registered signal handler for INT
20/12/10 08:11:41 INFO spark.SecurityManager: Changing view acls to: yarn,iabd2_group6
20/12/10 08:11:41 INFO spark.SecurityManager: Changing modify acls to: yarn,iabd2_group6
20/12/10 08:11:41 INFO spark.SecurityManager: Changing view acls groups to: 
20/12/10 08:11:41 INFO spark.SecurityManager: Changing modify acls groups to: 
20/12/10 08:11:41 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, iabd2_group6); groups with view permissions: Set(); users  with modify permissions: Set(yarn, iabd2_group6); groups with modify permissions: Set()
20/12/10 08:11:42 INFO client.TransportClientFactory: Successfully created connection to b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud/10.69.120.15:42493 after 159 ms (0 ms spent in bootstraps)
20/12/10 08:11:42 INFO spark.SecurityManager: Changing view acls to: yarn,iabd2_group6
20/12/10 08:11:42 INFO spark.SecurityManager: Changing modify acls to: yarn,iabd2_group6
20/12/10 08:11:42 INFO spark.SecurityManager: Changing view acls groups to: 
20/12/10 08:11:42 INFO spark.SecurityManager: Changing modify acls groups to: 
20/12/10 08:11:42 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, iabd2_group6); groups with view permissions: Set(); users  with modify permissions: Set(yarn, iabd2_group6); groups with modify permissions: Set()
20/12/10 08:11:42 INFO client.TransportClientFactory: Successfully created connection to b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud/10.69.120.15:42493 after 2 ms (0 ms spent in bootstraps)
20/12/10 08:11:42 INFO storage.DiskBlockManager: Created local directory at /yarn/nm/usercache/iabd2_group6/appcache/application_1606160497897_0548/blockmgr-95ea1fcf-4798-4fa7-b329-709056b4bac4
20/12/10 08:11:42 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB
20/12/10 08:11:43 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud:42493
20/12/10 08:11:43 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
20/12/10 08:11:43 INFO executor.Executor: Starting executor ID 1 on host e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud
20/12/10 08:11:43 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41795.
20/12/10 08:11:43 INFO netty.NettyBlockTransferService: Server created on e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud:41795
20/12/10 08:11:43 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/12/10 08:11:43 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(1, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, 41795, None)
20/12/10 08:11:43 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(1, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, 41795, None)
20/12/10 08:11:43 INFO storage.BlockManager: external shuffle service port = 7337
20/12/10 08:11:43 INFO storage.BlockManager: Registering executor with local external shuffle service.
20/12/10 08:11:43 INFO client.TransportClientFactory: Successfully created connection to e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud/10.69.120.23:7337 after 3 ms (0 ms spent in bootstraps)
20/12/10 08:11:43 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(1, e30311e3-e591-4cb5-a2d8-13cb65f9259a.priv.instances.scw.cloud, 41795, None)
20/12/10 08:11:43 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 0
20/12/10 08:11:43 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
20/12/10 08:11:43 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
20/12/10 08:11:43 INFO client.TransportClientFactory: Successfully created connection to b749ea52-ab37-40f7-b21b-a19f1efbff3f.priv.instances.scw.cloud/10.69.120.15:38827 after 7 ms (0 ms spent in bootstraps)
20/12/10 08:11:44 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 366.3 MB)
20/12/10 08:11:44 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 371 ms
20/12/10 08:11:44 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
20/12/10 08:11:45 INFO codegen.CodeGenerator: Code generated in 335.415494 ms
20/12/10 08:11:45 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_albums_releases_full.csv, range: 0-1152884, partition values: [empty row]
20/12/10 08:11:45 INFO codegen.CodeGenerator: Code generated in 17.554776 ms
20/12/10 08:11:45 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
20/12/10 08:11:45 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 49.8 KB, free 366.2 MB)
20/12/10 08:11:45 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 26 ms
20/12/10 08:11:45 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 709.6 KB, free 365.5 MB)
20/12/10 08:11:46 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 1485 bytes result sent to driver
20/12/10 08:11:49 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1
20/12/10 08:11:49 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)
20/12/10 08:11:49 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
20/12/10 08:11:49 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.1 KB, free 365.6 MB)
20/12/10 08:11:49 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 34 ms
20/12/10 08:11:50 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.3 KB, free 365.5 MB)
20/12/10 08:11:50 INFO codegen.CodeGenerator: Code generated in 16.338685 ms
20/12/10 08:11:51 INFO codegen.CodeGenerator: Code generated in 17.991264 ms
20/12/10 08:11:51 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_albums_releases_full.csv, range: 0-1152884, partition values: [empty row]
20/12/10 08:11:51 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
20/12/10 08:11:51 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 49.8 KB, free 365.5 MB)
20/12/10 08:11:51 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 25 ms
20/12/10 08:11:52 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 709.6 KB, free 364.8 MB)
20/12/10 08:11:52 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 1615 bytes result sent to driver
20/12/10 08:11:52 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2
20/12/10 08:11:52 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 2)
20/12/10 08:11:52 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
20/12/10 08:11:52 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 364.8 MB)
20/12/10 08:11:52 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 29 ms
20/12/10 08:11:52 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.8 KB, free 364.8 MB)
20/12/10 08:11:52 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_artists_releases_full.csv, range: 0-32339, partition values: [empty row]
20/12/10 08:11:52 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
20/12/10 08:11:52 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 49.8 KB, free 364.7 MB)
20/12/10 08:11:52 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 35 ms
20/12/10 08:11:52 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 709.6 KB, free 364.0 MB)
20/12/10 08:11:52 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 2). 1308 bytes result sent to driver
20/12/10 08:11:53 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3
20/12/10 08:11:53 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 3)
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.1 KB, free 364.8 MB)
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 31 ms
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 13.2 KB, free 364.8 MB)
20/12/10 08:11:53 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_artists_releases_full.csv, range: 0-32339, partition values: [empty row]
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 49.8 KB, free 364.7 MB)
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 21 ms
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 709.6 KB, free 364.1 MB)
20/12/10 08:11:53 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 3). 1502 bytes result sent to driver
20/12/10 08:11:53 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 4
20/12/10 08:11:53 INFO executor.Executor: Running task 0.0 in stage 4.0 (TID 4)
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 9
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.5 KB, free 364.1 MB)
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Reading broadcast variable 9 took 21 ms
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 8.8 KB, free 364.0 MB)
20/12/10 08:11:53 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_tracks_featured_full.csv, range: 0-1589492, partition values: [empty row]
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 8
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 49.8 KB, free 364.0 MB)
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Reading broadcast variable 8 took 21 ms
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 709.6 KB, free 363.3 MB)
20/12/10 08:11:53 INFO executor.Executor: Finished task 0.0 in stage 4.0 (TID 4). 1391 bytes result sent to driver
20/12/10 08:11:53 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 5
20/12/10 08:11:53 INFO executor.Executor: Running task 0.0 in stage 5.0 (TID 5)
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 11
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.1 KB, free 363.3 MB)
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Reading broadcast variable 11 took 20 ms
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.3 KB, free 363.3 MB)
20/12/10 08:11:53 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_tracks_featured_full.csv, range: 0-1589492, partition values: [empty row]
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 10
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 49.8 KB, free 363.2 MB)
20/12/10 08:11:53 INFO broadcast.TorrentBroadcast: Reading broadcast variable 10 took 25 ms
20/12/10 08:11:53 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 709.6 KB, free 362.5 MB)
20/12/10 08:11:53 INFO executor.Executor: Finished task 0.0 in stage 5.0 (TID 5). 1523 bytes result sent to driver
20/12/10 08:11:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 6
20/12/10 08:11:54 INFO executor.Executor: Running task 0.0 in stage 6.0 (TID 6)
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 13
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KB, free 362.5 MB)
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 13 took 15 ms
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.8 KB, free 362.5 MB)
20/12/10 08:11:54 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_tracks_releases_full.csv, range: 0-2148020, partition values: [empty row]
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 12
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 49.8 KB, free 362.5 MB)
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 12 took 19 ms
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 709.6 KB, free 361.8 MB)
20/12/10 08:11:54 INFO executor.Executor: Finished task 0.0 in stage 6.0 (TID 6). 1391 bytes result sent to driver
20/12/10 08:11:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 7
20/12/10 08:11:54 INFO executor.Executor: Running task 0.0 in stage 7.0 (TID 7)
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 15
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.1 KB, free 361.8 MB)
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 15 took 21 ms
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 13.3 KB, free 361.8 MB)
20/12/10 08:11:54 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_tracks_releases_full.csv, range: 0-2148020, partition values: [empty row]
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 14
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 49.8 KB, free 361.7 MB)
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 14 took 21 ms
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 709.6 KB, free 361.0 MB)
20/12/10 08:11:54 INFO executor.Executor: Finished task 0.0 in stage 7.0 (TID 7). 1566 bytes result sent to driver
20/12/10 08:11:54 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 8
20/12/10 08:11:54 INFO executor.Executor: Running task 0.0 in stage 8.0 (TID 8)
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 17
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.5 KB, free 361.0 MB)
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 17 took 18 ms
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 8.8 KB, free 361.0 MB)
20/12/10 08:11:54 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_playlists_featured_full.csv, range: 0-1313591, partition values: [empty row]
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 16
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 49.8 KB, free 361.0 MB)
20/12/10 08:11:54 INFO broadcast.TorrentBroadcast: Reading broadcast variable 16 took 21 ms
20/12/10 08:11:54 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 709.6 KB, free 360.3 MB)
20/12/10 08:11:54 INFO executor.Executor: Finished task 0.0 in stage 8.0 (TID 8). 1364 bytes result sent to driver
20/12/10 08:11:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 9
20/12/10 08:11:55 INFO executor.Executor: Running task 0.0 in stage 9.0 (TID 9)
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 19
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.1 KB, free 360.3 MB)
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Reading broadcast variable 19 took 18 ms
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 13.2 KB, free 360.2 MB)
20/12/10 08:11:55 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_playlists_featured_full.csv, range: 0-1313591, partition values: [empty row]
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 18
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 49.8 KB, free 360.2 MB)
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Reading broadcast variable 18 took 15 ms
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 709.6 KB, free 359.5 MB)
20/12/10 08:11:55 INFO executor.Executor: Finished task 0.0 in stage 9.0 (TID 9). 1635 bytes result sent to driver
20/12/10 08:11:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 10
20/12/10 08:11:55 INFO executor.Executor: Running task 0.0 in stage 10.0 (TID 10)
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 21
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.5 KB, free 359.5 MB)
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Reading broadcast variable 21 took 16 ms
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 8.8 KB, free 359.5 MB)
20/12/10 08:11:55 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_artists_featured_full.csv, range: 0-316788, partition values: [empty row]
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 20
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 49.8 KB, free 359.4 MB)
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Reading broadcast variable 20 took 19 ms
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 709.6 KB, free 358.8 MB)
20/12/10 08:11:55 INFO executor.Executor: Finished task 0.0 in stage 10.0 (TID 10). 1351 bytes result sent to driver
20/12/10 08:11:55 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 11
20/12/10 08:11:55 INFO executor.Executor: Running task 0.0 in stage 11.0 (TID 11)
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 23
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.1 KB, free 358.7 MB)
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Reading broadcast variable 23 took 17 ms
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 13.2 KB, free 358.7 MB)
20/12/10 08:11:55 INFO datasources.FileScanRDD: Reading File path: hdfs://d271ee89-3c06-4d40-b9d6-d3c1d65feb57.priv.instances.scw.cloud:8020/user/iabd2_group6/data/20201210/df_artists_featured_full.csv, range: 0-316788, partition values: [empty row]
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 22
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 49.8 KB, free 358.7 MB)
20/12/10 08:11:55 INFO broadcast.TorrentBroadcast: Reading broadcast variable 22 took 20 ms
20/12/10 08:11:55 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 709.6 KB, free 358.0 MB)
20/12/10 08:11:55 INFO executor.Executor: Finished task 0.0 in stage 11.0 (TID 11). 1545 bytes result sent to driver
20/12/10 08:11:55 INFO executor.CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/12/10 08:11:55 INFO memory.MemoryStore: MemoryStore cleared
20/12/10 08:11:55 INFO storage.BlockManager: BlockManager stopped
20/12/10 08:11:55 INFO util.ShutdownHookManager: Shutdown hook called

End of LogType:stderr
***********************************************************************


End of LogType:stdout
***********************************************************************

